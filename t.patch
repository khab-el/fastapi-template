diff --git a/.gitignore b/.gitignore
index 3fab427..83445cf 100644
--- a/.gitignore
+++ b/.gitignore
@@ -24,6 +24,7 @@ xunit-*.xml
 
 # PyCharm
 .idea/
+.vscode
 
 # virtual
 venv/
diff --git a/migrations/versions/219804a1d9e3_.py b/migrations/versions/219804a1d9e3_.py
deleted file mode 100644
index 1b18bc3..0000000
--- a/migrations/versions/219804a1d9e3_.py
+++ /dev/null
@@ -1,76 +0,0 @@
-"""empty message
-
-Revision ID: 219804a1d9e3
-Revises: 
-Create Date: 2023-09-04 11:27:16.356037
-
-"""
-from alembic import op
-import sqlalchemy as sa
-
-
-# revision identifiers, used by Alembic.
-revision = "219804a1d9e3"
-down_revision = None
-branch_labels = None
-depends_on = None
-
-
-def upgrade():
-    # Preprocess
-    pre_upgrade()
-
-    # ### commands auto generated by Alembic - please adjust! ###
-    op.create_table(
-        "user",
-        sa.Column("username", sa.String(length=255), nullable=False),
-        sa.Column("phone", sa.String(length=255), nullable=True),
-        sa.Column("email", sa.String(length=255), nullable=False),
-        sa.Column("created_at", sa.DateTime(), server_default=sa.FetchedValue(), nullable=True),
-        sa.Column("updated_at", sa.DateTime(), server_default=sa.FetchedValue(), nullable=True),
-        sa.Column("deleted_at", sa.DateTime(), server_default=sa.FetchedValue(), nullable=True),
-        sa.Column("id", sa.UUID(), server_default=sa.text("gen_random_uuid()"), nullable=False),
-        sa.PrimaryKeyConstraint("id"),
-        sa.UniqueConstraint("email"),
-        sa.UniqueConstraint("username"),
-    )
-    op.create_index(op.f("ix_user_email"), "user", ["email"], unique=False)
-    op.create_index(op.f("ix_user_id"), "user", ["id"], unique=False)
-    # ### end Alembic commands ###
-
-    # Postprocess
-    post_upgrade()
-
-
-def downgrade():
-    # Preprocess
-    pre_downgrade()
-
-    # ### commands auto generated by Alembic - please adjust! ###
-    op.drop_index(op.f("ix_user_id"), table_name="user")
-    op.drop_index(op.f("ix_user_email"), table_name="user")
-    op.drop_table("user")
-    # ### end Alembic commands ###
-
-    # Postprocess
-    post_downgrade()
-
-
-def pre_upgrade():
-    # Processing before upgrading the schema
-    pass
-
-
-def post_upgrade():
-    # Processing after upgrading the schema
-    pass
-
-
-def pre_downgrade():
-    # Processing before downgrading the schema
-    pass
-
-
-def post_downgrade():
-    # Processing after downgrading the schema
-    pass
diff --git a/migrations/versions/5e083a6ce7fe_.py b/migrations/versions/5e235bbba1fc_.py
similarity index 79%
rename from migrations/versions/5e083a6ce7fe_.py
rename to migrations/versions/5e235bbba1fc_.py
index 4024b34..b58c749 100644
--- a/migrations/versions/5e083a6ce7fe_.py
+++ b/migrations/versions/5e235bbba1fc_.py
@@ -1,8 +1,8 @@
 """empty message
 
-Revision ID: 5e083a6ce7fe
-Revises: 219804a1d9e3
-Create Date: 2023-09-05 14:14:04.294167
+Revision ID: 5e235bbba1fc
+Revises: 
+Create Date: 2023-09-13 20:24:38.767450
 
 """
 from alembic import op
@@ -11,8 +11,8 @@ from sqlalchemy import FetchedValue
 
 
 # revision identifiers, used by Alembic.
-revision = "5e083a6ce7fe"
-down_revision = "219804a1d9e3"
+revision = "5e235bbba1fc"
+down_revision = None
 branch_labels = None
 depends_on = None
 
@@ -24,13 +24,13 @@ def upgrade():
     # ### commands auto generated by Alembic - please adjust! ###
     op.create_table(
         "category",
-        sa.Column("id", sa.UUID(), server_default=sa.text("gen_random_uuid()"), nullable=False),
         sa.Column("category_title", sa.String(length=255), nullable=True),
         sa.Column("category_description", sa.String(length=255), nullable=True),
         sa.Column("parent_category_id", sa.UUID(), nullable=True),
-        sa.Column("created_at", sa.DateTime(), server_default=FetchedValue(), nullable=True),
-        sa.Column("updated_at", sa.DateTime(), server_default=FetchedValue(), nullable=True),
-        sa.Column("deleted_at", sa.DateTime(), server_default=FetchedValue(), nullable=True),
+        sa.Column("created_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
+        sa.Column("updated_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
+        sa.Column("deleted_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
+        sa.Column("id", sa.UUID(), server_default=sa.text("gen_random_uuid()"), nullable=False),
         sa.ForeignKeyConstraint(
             ["parent_category_id"],
             ["category.id"],
@@ -44,13 +44,28 @@ def upgrade():
         sa.Column("phone", sa.String(length=255), nullable=True),
         sa.Column("email", sa.String(length=255), nullable=True),
         sa.Column("additional_info", sa.String(length=255), nullable=True),
-        sa.Column("created_at", sa.DateTime(), server_default=FetchedValue(), nullable=True),
-        sa.Column("updated_at", sa.DateTime(), server_default=FetchedValue(), nullable=True),
-        sa.Column("deleted_at", sa.DateTime(), server_default=FetchedValue(), nullable=True),
+        sa.Column("created_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
+        sa.Column("updated_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
+        sa.Column("deleted_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
         sa.Column("id", sa.UUID(), server_default=sa.text("gen_random_uuid()"), nullable=False),
         sa.PrimaryKeyConstraint("id"),
     )
     op.create_index(op.f("ix_providercontact_id"), "providercontact", ["id"], unique=False)
+    op.create_table(
+        "user",
+        sa.Column("username", sa.String(length=255), nullable=False),
+        sa.Column("phone", sa.String(length=255), nullable=True),
+        sa.Column("email", sa.String(length=255), nullable=False),
+        sa.Column("created_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
+        sa.Column("updated_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
+        sa.Column("deleted_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
+        sa.Column("id", sa.UUID(), server_default=sa.text("gen_random_uuid()"), nullable=False),
+        sa.PrimaryKeyConstraint("id"),
+        sa.UniqueConstraint("email"),
+        sa.UniqueConstraint("username"),
+    )
+    op.create_index(op.f("ix_user_email"), "user", ["email"], unique=False)
+    op.create_index(op.f("ix_user_id"), "user", ["id"], unique=False)
     op.create_table(
         "providerenity",
         sa.Column("address", sa.String(length=255), nullable=True),
@@ -59,9 +74,9 @@ def upgrade():
         sa.Column("lat", sa.Numeric(precision=8, scale=6), nullable=True),
         sa.Column("lon", sa.Numeric(precision=8, scale=6), nullable=True),
         sa.Column("provider_contact_id", sa.UUID(), nullable=True),
-        sa.Column("created_at", sa.DateTime(), server_default=FetchedValue(), nullable=True),
-        sa.Column("updated_at", sa.DateTime(), server_default=FetchedValue(), nullable=True),
-        sa.Column("deleted_at", sa.DateTime(), server_default=FetchedValue(), nullable=True),
+        sa.Column("created_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
+        sa.Column("updated_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
+        sa.Column("deleted_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
         sa.Column("id", sa.UUID(), server_default=sa.text("gen_random_uuid()"), nullable=False),
         sa.ForeignKeyConstraint(
             ["provider_contact_id"],
@@ -88,9 +103,9 @@ def upgrade():
         sa.Column("url", sa.String(length=255), nullable=True),
         sa.Column("operating_hours", sa.String(length=255), nullable=True),
         sa.Column("provider_entity_id", sa.UUID(), nullable=True),
-        sa.Column("created_at", sa.DateTime(), server_default=FetchedValue(), nullable=True),
-        sa.Column("updated_at", sa.DateTime(), server_default=FetchedValue(), nullable=True),
-        sa.Column("deleted_at", sa.DateTime(), server_default=FetchedValue(), nullable=True),
+        sa.Column("created_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
+        sa.Column("updated_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
+        sa.Column("deleted_at", sa.DateTime(), server_default=FetchedValue(), nullable=False),
         sa.Column("id", sa.UUID(), server_default=sa.text("gen_random_uuid()"), nullable=False),
         sa.ForeignKeyConstraint(
             ["provider_entity_id"],
@@ -103,7 +118,6 @@ def upgrade():
         "category_x_service",
         sa.Column("category_id", sa.UUID(), nullable=False),
         sa.Column("service_id", sa.UUID(), nullable=False),
-        sa.Column("id", sa.UUID(), server_default=sa.text("gen_random_uuid()"), nullable=False),
         sa.ForeignKeyConstraint(
             ["category_id"],
             ["category.id"],
@@ -112,9 +126,8 @@ def upgrade():
             ["service_id"],
             ["service.id"],
         ),
-        sa.PrimaryKeyConstraint("category_id", "service_id", "id"),
+        sa.PrimaryKeyConstraint("category_id", "service_id"),
     )
-    op.create_index(op.f("ix_category_x_service_id"), "category_x_service", ["id"], unique=False)
     # ### end Alembic commands ###
 
     # Postprocess
@@ -126,7 +139,6 @@ def downgrade():
     pre_downgrade()
 
     # ### commands auto generated by Alembic - please adjust! ###
-    op.drop_index(op.f("ix_category_x_service_id"), table_name="category_x_service")
     op.drop_table("category_x_service")
     op.drop_index(op.f("ix_service_id"), table_name="service")
     op.drop_table("service")
@@ -134,6 +146,9 @@ def downgrade():
     op.drop_table("providerphoto")
     op.drop_index(op.f("ix_providerenity_id"), table_name="providerenity")
     op.drop_table("providerenity")
+    op.drop_index(op.f("ix_user_id"), table_name="user")
+    op.drop_index(op.f("ix_user_email"), table_name="user")
+    op.drop_table("user")
     op.drop_index(op.f("ix_providercontact_id"), table_name="providercontact")
     op.drop_table("providercontact")
     op.drop_index(op.f("ix_category_id"), table_name="category")
diff --git a/poetry.lock b/poetry.lock
index ea0a313..a5e072e 100644
--- a/poetry.lock
+++ b/poetry.lock
@@ -2,14 +2,14 @@
 
 [[package]]
 name = "add-trailing-comma"
-version = "3.0.1"
+version = "3.1.0"
 description = "Automatically add trailing commas to calls and literals"
 category = "dev"
 optional = false
 python-versions = ">=3.8"
 files = [
-    {file = "add_trailing_comma-3.0.1-py2.py3-none-any.whl", hash = "sha256:92939ba323f6289dc405772eb935044112a7804ceb9beae595a826b894b3d164"},
-    {file = "add_trailing_comma-3.0.1.tar.gz", hash = "sha256:b0a65ecf9c5a34f3bccb97e0dffcc62487b29084ae509eeea59960881f55533d"},
+    {file = "add_trailing_comma-3.1.0-py2.py3-none-any.whl", hash = "sha256:160207e2ac414a841a71f4f5095f7350f87af460aab3dfe36cfa037992530e5c"},
+    {file = "add_trailing_comma-3.1.0.tar.gz", hash = "sha256:b255319d7ef6dca308b051ffd80fccf98c018879744c7c7e03083b2eee079c45"},
 ]
 
 [package.dependencies]
@@ -200,14 +200,14 @@ files = [
 
 [[package]]
 name = "anyio"
-version = "3.7.1"
+version = "4.0.0"
 description = "High level compatibility layer for multiple asynchronous event loop implementations"
 category = "main"
 optional = false
-python-versions = ">=3.7"
+python-versions = ">=3.8"
 files = [
-    {file = "anyio-3.7.1-py3-none-any.whl", hash = "sha256:91dee416e570e92c64041bd18b900d1d6fa78dff7048769ce5ac5ddad004fbb5"},
-    {file = "anyio-3.7.1.tar.gz", hash = "sha256:44a3c9aba0f5defa43261a8b3efb97891f2bd7d804e0e1f56419befa1adfc780"},
+    {file = "anyio-4.0.0-py3-none-any.whl", hash = "sha256:cfdb2b588b9fc25ede96d8db56ed50848b0b649dca3dd1df0b11f683bb9e0b5f"},
+    {file = "anyio-4.0.0.tar.gz", hash = "sha256:f7ed51751b2c2add651e5747c891b47e26d2a21be5d32d9311dfe9692f3e5d7a"},
 ]
 
 [package.dependencies]
@@ -215,9 +215,9 @@ idna = ">=2.8"
 sniffio = ">=1.1"
 
 [package.extras]
-doc = ["Sphinx", "packaging", "sphinx-autodoc-typehints (>=1.2.0)", "sphinx-rtd-theme (>=1.2.2)", "sphinxcontrib-jquery"]
-test = ["anyio[trio]", "coverage[toml] (>=4.5)", "hypothesis (>=4.0)", "mock (>=4)", "psutil (>=5.9)", "pytest (>=7.0)", "pytest-mock (>=3.6.1)", "trustme", "uvloop (>=0.17)"]
-trio = ["trio (<0.22)"]
+doc = ["Sphinx (>=7)", "packaging", "sphinx-autodoc-typehints (>=1.2.0)"]
+test = ["anyio[trio]", "coverage[toml] (>=7)", "hypothesis (>=4.0)", "psutil (>=5.9)", "pytest (>=7.0)", "pytest-mock (>=3.6.1)", "trustme", "uvloop (>=0.17)"]
+trio = ["trio (>=0.22)"]
 
 [[package]]
 name = "astor"
@@ -334,14 +334,14 @@ tests-no-zope = ["cloudpickle", "hypothesis", "mypy (>=1.1.1)", "pympler", "pyte
 
 [[package]]
 name = "autoflake"
-version = "2.2.0"
+version = "2.2.1"
 description = "Removes unused imports and unused variables"
 category = "dev"
 optional = false
 python-versions = ">=3.8"
 files = [
-    {file = "autoflake-2.2.0-py3-none-any.whl", hash = "sha256:de409b009a34c1c2a7cc2aae84c4c05047f9773594317c6a6968bd497600d4a0"},
-    {file = "autoflake-2.2.0.tar.gz", hash = "sha256:62e1f74a0fdad898a96fee6f99fe8241af90ad99c7110c884b35855778412251"},
+    {file = "autoflake-2.2.1-py3-none-any.whl", hash = "sha256:265cde0a43c1f44ecfb4f30d95b0437796759d07be7706a2f70e4719234c0f79"},
+    {file = "autoflake-2.2.1.tar.gz", hash = "sha256:62b7b6449a692c3c9b0c916919bbc21648da7281e8506bcf8d3f8280e431ebc1"},
 ]
 
 [package.dependencies]
@@ -657,64 +657,64 @@ files = [
 
 [[package]]
 name = "coverage"
-version = "7.3.0"
+version = "7.3.1"
 description = "Code coverage measurement for Python"
 category = "dev"
 optional = false
 python-versions = ">=3.8"
 files = [
-    {file = "coverage-7.3.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:db76a1bcb51f02b2007adacbed4c88b6dee75342c37b05d1822815eed19edee5"},
-    {file = "coverage-7.3.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:c02cfa6c36144ab334d556989406837336c1d05215a9bdf44c0bc1d1ac1cb637"},
-    {file = "coverage-7.3.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:477c9430ad5d1b80b07f3c12f7120eef40bfbf849e9e7859e53b9c93b922d2af"},
-    {file = "coverage-7.3.0-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ce2ee86ca75f9f96072295c5ebb4ef2a43cecf2870b0ca5e7a1cbdd929cf67e1"},
-    {file = "coverage-7.3.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:68d8a0426b49c053013e631c0cdc09b952d857efa8f68121746b339912d27a12"},
-    {file = "coverage-7.3.0-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:b3eb0c93e2ea6445b2173da48cb548364f8f65bf68f3d090404080d338e3a689"},
-    {file = "coverage-7.3.0-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:90b6e2f0f66750c5a1178ffa9370dec6c508a8ca5265c42fbad3ccac210a7977"},
-    {file = "coverage-7.3.0-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:96d7d761aea65b291a98c84e1250cd57b5b51726821a6f2f8df65db89363be51"},
-    {file = "coverage-7.3.0-cp310-cp310-win32.whl", hash = "sha256:63c5b8ecbc3b3d5eb3a9d873dec60afc0cd5ff9d9f1c75981d8c31cfe4df8527"},
-    {file = "coverage-7.3.0-cp310-cp310-win_amd64.whl", hash = "sha256:97c44f4ee13bce914272589b6b41165bbb650e48fdb7bd5493a38bde8de730a1"},
-    {file = "coverage-7.3.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:74c160285f2dfe0acf0f72d425f3e970b21b6de04157fc65adc9fd07ee44177f"},
-    {file = "coverage-7.3.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:b543302a3707245d454fc49b8ecd2c2d5982b50eb63f3535244fd79a4be0c99d"},
-    {file = "coverage-7.3.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ad0f87826c4ebd3ef484502e79b39614e9c03a5d1510cfb623f4a4a051edc6fd"},
-    {file = "coverage-7.3.0-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:13c6cbbd5f31211d8fdb477f0f7b03438591bdd077054076eec362cf2207b4a7"},
-    {file = "coverage-7.3.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fac440c43e9b479d1241fe9d768645e7ccec3fb65dc3a5f6e90675e75c3f3e3a"},
-    {file = "coverage-7.3.0-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:3c9834d5e3df9d2aba0275c9f67989c590e05732439b3318fa37a725dff51e74"},
-    {file = "coverage-7.3.0-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:4c8e31cf29b60859876474034a83f59a14381af50cbe8a9dbaadbf70adc4b214"},
-    {file = "coverage-7.3.0-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:7a9baf8e230f9621f8e1d00c580394a0aa328fdac0df2b3f8384387c44083c0f"},
-    {file = "coverage-7.3.0-cp311-cp311-win32.whl", hash = "sha256:ccc51713b5581e12f93ccb9c5e39e8b5d4b16776d584c0f5e9e4e63381356482"},
-    {file = "coverage-7.3.0-cp311-cp311-win_amd64.whl", hash = "sha256:887665f00ea4e488501ba755a0e3c2cfd6278e846ada3185f42d391ef95e7e70"},
-    {file = "coverage-7.3.0-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:d000a739f9feed900381605a12a61f7aaced6beae832719ae0d15058a1e81c1b"},
-    {file = "coverage-7.3.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:59777652e245bb1e300e620ce2bef0d341945842e4eb888c23a7f1d9e143c446"},
-    {file = "coverage-7.3.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c9737bc49a9255d78da085fa04f628a310c2332b187cd49b958b0e494c125071"},
-    {file = "coverage-7.3.0-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:5247bab12f84a1d608213b96b8af0cbb30d090d705b6663ad794c2f2a5e5b9fe"},
-    {file = "coverage-7.3.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e2ac9a1de294773b9fa77447ab7e529cf4fe3910f6a0832816e5f3d538cfea9a"},
-    {file = "coverage-7.3.0-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:85b7335c22455ec12444cec0d600533a238d6439d8d709d545158c1208483873"},
-    {file = "coverage-7.3.0-cp312-cp312-musllinux_1_1_i686.whl", hash = "sha256:36ce5d43a072a036f287029a55b5c6a0e9bd73db58961a273b6dc11a2c6eb9c2"},
-    {file = "coverage-7.3.0-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:211a4576e984f96d9fce61766ffaed0115d5dab1419e4f63d6992b480c2bd60b"},
-    {file = "coverage-7.3.0-cp312-cp312-win32.whl", hash = "sha256:56afbf41fa4a7b27f6635bc4289050ac3ab7951b8a821bca46f5b024500e6321"},
-    {file = "coverage-7.3.0-cp312-cp312-win_amd64.whl", hash = "sha256:7f297e0c1ae55300ff688568b04ff26b01c13dfbf4c9d2b7d0cb688ac60df479"},
-    {file = "coverage-7.3.0-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:ac0dec90e7de0087d3d95fa0533e1d2d722dcc008bc7b60e1143402a04c117c1"},
-    {file = "coverage-7.3.0-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:438856d3f8f1e27f8e79b5410ae56650732a0dcfa94e756df88c7e2d24851fcd"},
-    {file = "coverage-7.3.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1084393c6bda8875c05e04fce5cfe1301a425f758eb012f010eab586f1f3905e"},
-    {file = "coverage-7.3.0-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:49ab200acf891e3dde19e5aa4b0f35d12d8b4bd805dc0be8792270c71bd56c54"},
-    {file = "coverage-7.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a67e6bbe756ed458646e1ef2b0778591ed4d1fcd4b146fc3ba2feb1a7afd4254"},
-    {file = "coverage-7.3.0-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:8f39c49faf5344af36042b293ce05c0d9004270d811c7080610b3e713251c9b0"},
-    {file = "coverage-7.3.0-cp38-cp38-musllinux_1_1_i686.whl", hash = "sha256:7df91fb24c2edaabec4e0eee512ff3bc6ec20eb8dccac2e77001c1fe516c0c84"},
-    {file = "coverage-7.3.0-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:34f9f0763d5fa3035a315b69b428fe9c34d4fc2f615262d6be3d3bf3882fb985"},
-    {file = "coverage-7.3.0-cp38-cp38-win32.whl", hash = "sha256:bac329371d4c0d456e8d5f38a9b0816b446581b5f278474e416ea0c68c47dcd9"},
-    {file = "coverage-7.3.0-cp38-cp38-win_amd64.whl", hash = "sha256:b859128a093f135b556b4765658d5d2e758e1fae3e7cc2f8c10f26fe7005e543"},
-    {file = "coverage-7.3.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:fc0ed8d310afe013db1eedd37176d0839dc66c96bcfcce8f6607a73ffea2d6ba"},
-    {file = "coverage-7.3.0-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:e61260ec93f99f2c2d93d264b564ba912bec502f679793c56f678ba5251f0393"},
-    {file = "coverage-7.3.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:97af9554a799bd7c58c0179cc8dbf14aa7ab50e1fd5fa73f90b9b7215874ba28"},
-    {file = "coverage-7.3.0-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:3558e5b574d62f9c46b76120a5c7c16c4612dc2644c3d48a9f4064a705eaee95"},
-    {file = "coverage-7.3.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:37d5576d35fcb765fca05654f66aa71e2808d4237d026e64ac8b397ffa66a56a"},
-    {file = "coverage-7.3.0-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:07ea61bcb179f8f05ffd804d2732b09d23a1238642bf7e51dad62082b5019b34"},
-    {file = "coverage-7.3.0-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:80501d1b2270d7e8daf1b64b895745c3e234289e00d5f0e30923e706f110334e"},
-    {file = "coverage-7.3.0-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:4eddd3153d02204f22aef0825409091a91bf2a20bce06fe0f638f5c19a85de54"},
-    {file = "coverage-7.3.0-cp39-cp39-win32.whl", hash = "sha256:2d22172f938455c156e9af2612650f26cceea47dc86ca048fa4e0b2d21646ad3"},
-    {file = "coverage-7.3.0-cp39-cp39-win_amd64.whl", hash = "sha256:60f64e2007c9144375dd0f480a54d6070f00bb1a28f65c408370544091c9bc9e"},
-    {file = "coverage-7.3.0-pp38.pp39.pp310-none-any.whl", hash = "sha256:5492a6ce3bdb15c6ad66cb68a0244854d9917478877a25671d70378bdc8562d0"},
-    {file = "coverage-7.3.0.tar.gz", hash = "sha256:49dbb19cdcafc130f597d9e04a29d0a032ceedf729e41b181f51cd170e6ee865"},
+    {file = "coverage-7.3.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:cd0f7429ecfd1ff597389907045ff209c8fdb5b013d38cfa7c60728cb484b6e3"},
+    {file = "coverage-7.3.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:966f10df9b2b2115da87f50f6a248e313c72a668248be1b9060ce935c871f276"},
+    {file = "coverage-7.3.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0575c37e207bb9b98b6cf72fdaaa18ac909fb3d153083400c2d48e2e6d28bd8e"},
+    {file = "coverage-7.3.1-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:245c5a99254e83875c7fed8b8b2536f040997a9b76ac4c1da5bff398c06e860f"},
+    {file = "coverage-7.3.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:4c96dd7798d83b960afc6c1feb9e5af537fc4908852ef025600374ff1a017392"},
+    {file = "coverage-7.3.1-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:de30c1aa80f30af0f6b2058a91505ea6e36d6535d437520067f525f7df123887"},
+    {file = "coverage-7.3.1-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:50dd1e2dd13dbbd856ffef69196781edff26c800a74f070d3b3e3389cab2600d"},
+    {file = "coverage-7.3.1-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:b9c0c19f70d30219113b18fe07e372b244fb2a773d4afde29d5a2f7930765136"},
+    {file = "coverage-7.3.1-cp310-cp310-win32.whl", hash = "sha256:770f143980cc16eb601ccfd571846e89a5fe4c03b4193f2e485268f224ab602f"},
+    {file = "coverage-7.3.1-cp310-cp310-win_amd64.whl", hash = "sha256:cdd088c00c39a27cfa5329349cc763a48761fdc785879220d54eb785c8a38520"},
+    {file = "coverage-7.3.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:74bb470399dc1989b535cb41f5ca7ab2af561e40def22d7e188e0a445e7639e3"},
+    {file = "coverage-7.3.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:025ded371f1ca280c035d91b43252adbb04d2aea4c7105252d3cbc227f03b375"},
+    {file = "coverage-7.3.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a6191b3a6ad3e09b6cfd75b45c6aeeffe7e3b0ad46b268345d159b8df8d835f9"},
+    {file = "coverage-7.3.1-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:7eb0b188f30e41ddd659a529e385470aa6782f3b412f860ce22b2491c89b8593"},
+    {file = "coverage-7.3.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:75c8f0df9dfd8ff745bccff75867d63ef336e57cc22b2908ee725cc552689ec8"},
+    {file = "coverage-7.3.1-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:7eb3cd48d54b9bd0e73026dedce44773214064be93611deab0b6a43158c3d5a0"},
+    {file = "coverage-7.3.1-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:ac3c5b7e75acac31e490b7851595212ed951889918d398b7afa12736c85e13ce"},
+    {file = "coverage-7.3.1-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:5b4ee7080878077af0afa7238df1b967f00dc10763f6e1b66f5cced4abebb0a3"},
+    {file = "coverage-7.3.1-cp311-cp311-win32.whl", hash = "sha256:229c0dd2ccf956bf5aeede7e3131ca48b65beacde2029f0361b54bf93d36f45a"},
+    {file = "coverage-7.3.1-cp311-cp311-win_amd64.whl", hash = "sha256:c6f55d38818ca9596dc9019eae19a47410d5322408140d9a0076001a3dcb938c"},
+    {file = "coverage-7.3.1-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:5289490dd1c3bb86de4730a92261ae66ea8d44b79ed3cc26464f4c2cde581fbc"},
+    {file = "coverage-7.3.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:ca833941ec701fda15414be400c3259479bfde7ae6d806b69e63b3dc423b1832"},
+    {file = "coverage-7.3.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:cd694e19c031733e446c8024dedd12a00cda87e1c10bd7b8539a87963685e969"},
+    {file = "coverage-7.3.1-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:aab8e9464c00da5cb9c536150b7fbcd8850d376d1151741dd0d16dfe1ba4fd26"},
+    {file = "coverage-7.3.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:87d38444efffd5b056fcc026c1e8d862191881143c3aa80bb11fcf9dca9ae204"},
+    {file = "coverage-7.3.1-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:8a07b692129b8a14ad7a37941a3029c291254feb7a4237f245cfae2de78de037"},
+    {file = "coverage-7.3.1-cp312-cp312-musllinux_1_1_i686.whl", hash = "sha256:2829c65c8faaf55b868ed7af3c7477b76b1c6ebeee99a28f59a2cb5907a45760"},
+    {file = "coverage-7.3.1-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:1f111a7d85658ea52ffad7084088277135ec5f368457275fc57f11cebb15607f"},
+    {file = "coverage-7.3.1-cp312-cp312-win32.whl", hash = "sha256:c397c70cd20f6df7d2a52283857af622d5f23300c4ca8e5bd8c7a543825baa5a"},
+    {file = "coverage-7.3.1-cp312-cp312-win_amd64.whl", hash = "sha256:5ae4c6da8b3d123500f9525b50bf0168023313963e0e2e814badf9000dd6ef92"},
+    {file = "coverage-7.3.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:ca70466ca3a17460e8fc9cea7123c8cbef5ada4be3140a1ef8f7b63f2f37108f"},
+    {file = "coverage-7.3.1-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:f2781fd3cabc28278dc982a352f50c81c09a1a500cc2086dc4249853ea96b981"},
+    {file = "coverage-7.3.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:6407424621f40205bbe6325686417e5e552f6b2dba3535dd1f90afc88a61d465"},
+    {file = "coverage-7.3.1-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:04312b036580ec505f2b77cbbdfb15137d5efdfade09156961f5277149f5e344"},
+    {file = "coverage-7.3.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ac9ad38204887349853d7c313f53a7b1c210ce138c73859e925bc4e5d8fc18e7"},
+    {file = "coverage-7.3.1-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:53669b79f3d599da95a0afbef039ac0fadbb236532feb042c534fbb81b1a4e40"},
+    {file = "coverage-7.3.1-cp38-cp38-musllinux_1_1_i686.whl", hash = "sha256:614f1f98b84eb256e4f35e726bfe5ca82349f8dfa576faabf8a49ca09e630086"},
+    {file = "coverage-7.3.1-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:f1a317fdf5c122ad642db8a97964733ab7c3cf6009e1a8ae8821089993f175ff"},
+    {file = "coverage-7.3.1-cp38-cp38-win32.whl", hash = "sha256:defbbb51121189722420a208957e26e49809feafca6afeef325df66c39c4fdb3"},
+    {file = "coverage-7.3.1-cp38-cp38-win_amd64.whl", hash = "sha256:f4f456590eefb6e1b3c9ea6328c1e9fa0f1006e7481179d749b3376fc793478e"},
+    {file = "coverage-7.3.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:f12d8b11a54f32688b165fd1a788c408f927b0960984b899be7e4c190ae758f1"},
+    {file = "coverage-7.3.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:f09195dda68d94a53123883de75bb97b0e35f5f6f9f3aa5bf6e496da718f0cb6"},
+    {file = "coverage-7.3.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c6601a60318f9c3945be6ea0f2a80571f4299b6801716f8a6e4846892737ebe4"},
+    {file = "coverage-7.3.1-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:07d156269718670d00a3b06db2288b48527fc5f36859425ff7cec07c6b367745"},
+    {file = "coverage-7.3.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:636a8ac0b044cfeccae76a36f3b18264edcc810a76a49884b96dd744613ec0b7"},
+    {file = "coverage-7.3.1-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:5d991e13ad2ed3aced177f524e4d670f304c8233edad3210e02c465351f785a0"},
+    {file = "coverage-7.3.1-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:586649ada7cf139445da386ab6f8ef00e6172f11a939fc3b2b7e7c9082052fa0"},
+    {file = "coverage-7.3.1-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:4aba512a15a3e1e4fdbfed2f5392ec221434a614cc68100ca99dcad7af29f3f8"},
+    {file = "coverage-7.3.1-cp39-cp39-win32.whl", hash = "sha256:6bc6f3f4692d806831c136c5acad5ccedd0262aa44c087c46b7101c77e139140"},
+    {file = "coverage-7.3.1-cp39-cp39-win_amd64.whl", hash = "sha256:553d7094cb27db58ea91332e8b5681bac107e7242c23f7629ab1316ee73c4981"},
+    {file = "coverage-7.3.1-pp38.pp39.pp310-none-any.whl", hash = "sha256:220eb51f5fb38dfdb7e5d54284ca4d0cd70ddac047d750111a68ab1798945194"},
+    {file = "coverage-7.3.1.tar.gz", hash = "sha256:6cb7fe1581deb67b782c153136541e20901aa312ceedaf1467dcb35255787952"},
 ]
 
 [package.extras]
@@ -827,19 +827,19 @@ all = ["email-validator (>=2.0.0)", "httpx (>=0.23.0)", "itsdangerous (>=1.1.0)"
 
 [[package]]
 name = "filelock"
-version = "3.12.2"
+version = "3.12.3"
 description = "A platform independent file lock."
 category = "dev"
 optional = false
-python-versions = ">=3.7"
+python-versions = ">=3.8"
 files = [
-    {file = "filelock-3.12.2-py3-none-any.whl", hash = "sha256:cbb791cdea2a72f23da6ac5b5269ab0a0d161e9ef0100e653b69049a7706d1ec"},
-    {file = "filelock-3.12.2.tar.gz", hash = "sha256:002740518d8aa59a26b0c76e10fb8c6e15eae825d34b6fdf670333fd7b938d81"},
+    {file = "filelock-3.12.3-py3-none-any.whl", hash = "sha256:f067e40ccc40f2b48395a80fcbd4728262fab54e232e090a4063ab804179efeb"},
+    {file = "filelock-3.12.3.tar.gz", hash = "sha256:0ecc1dd2ec4672a10c8550a8182f1bd0c0a5088470ecd5a125e45f49472fac3d"},
 ]
 
 [package.extras]
-docs = ["furo (>=2023.5.20)", "sphinx (>=7.0.1)", "sphinx-autodoc-typehints (>=1.23,!=1.23.4)"]
-testing = ["covdefaults (>=2.3)", "coverage (>=7.2.7)", "diff-cover (>=7.5)", "pytest (>=7.3.1)", "pytest-cov (>=4.1)", "pytest-mock (>=3.10)", "pytest-timeout (>=2.1)"]
+docs = ["furo (>=2023.7.26)", "sphinx (>=7.1.2)", "sphinx-autodoc-typehints (>=1.24)"]
+testing = ["covdefaults (>=2.3)", "coverage (>=7.3)", "diff-cover (>=7.7)", "pytest (>=7.4)", "pytest-cov (>=4.1)", "pytest-mock (>=3.11.1)", "pytest-timeout (>=2.1)"]
 
 [[package]]
 name = "flake8"
@@ -1030,6 +1030,23 @@ files = [
     {file = "flake8_module_name-0.2.0.tar.gz", hash = "sha256:cea3b8cb6ae8d82b9be8a1501d33f805d65f76aa6c3d793126898ac70ba9e48b"},
 ]
 
+[[package]]
+name = "flake8-mypy"
+version = "17.8.0"
+description = "A plugin for flake8 integrating mypy."
+category = "dev"
+optional = false
+python-versions = "*"
+files = [
+    {file = "flake8-mypy-17.8.0.tar.gz", hash = "sha256:47120db63aff631ee1f84bac6fe8e64731dc66da3efc1c51f85e15ade4a3ba18"},
+    {file = "flake8_mypy-17.8.0-py35.py36-none-any.whl", hash = "sha256:cff009f4250e8391bf48990093cff85802778c345c8449d6498b62efefeebcbc"},
+]
+
+[package.dependencies]
+attrs = "*"
+flake8 = ">=3.0.0"
+mypy = "*"
+
 [[package]]
 name = "flake8-pep3101"
 version = "2.0.0"
@@ -1229,19 +1246,22 @@ smmap = ">=3.0.1,<6"
 
 [[package]]
 name = "gitpython"
-version = "3.1.32"
+version = "3.1.36"
 description = "GitPython is a Python library used to interact with Git repositories"
 category = "dev"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "GitPython-3.1.32-py3-none-any.whl", hash = "sha256:e3d59b1c2c6ebb9dfa7a184daf3b6dd4914237e7488a1730a6d8f6f5d0b4187f"},
-    {file = "GitPython-3.1.32.tar.gz", hash = "sha256:8d9b8cb1e80b9735e8717c9362079d3ce4c6e5ddeebedd0361b228c3a67a62f6"},
+    {file = "GitPython-3.1.36-py3-none-any.whl", hash = "sha256:8d22b5cfefd17c79914226982bb7851d6ade47545b1735a9d010a2a4c26d8388"},
+    {file = "GitPython-3.1.36.tar.gz", hash = "sha256:4bb0c2a6995e85064140d31a33289aa5dce80133a23d36fcd372d716c54d3ebf"},
 ]
 
 [package.dependencies]
 gitdb = ">=4.0.1,<5"
 
+[package.extras]
+test = ["black", "coverage[toml]", "ddt (>=1.1.1,!=1.4.3)", "mypy", "pre-commit", "pytest", "pytest-cov", "pytest-sugar", "virtualenv"]
+
 [[package]]
 name = "greenlet"
 version = "2.0.2"
@@ -1397,14 +1417,14 @@ socks = ["socksio (>=1.0.0,<2.0.0)"]
 
 [[package]]
 name = "identify"
-version = "2.5.27"
+version = "2.5.28"
 description = "File identification library for Python"
 category = "dev"
 optional = false
 python-versions = ">=3.8"
 files = [
-    {file = "identify-2.5.27-py2.py3-none-any.whl", hash = "sha256:fdb527b2dfe24602809b2201e033c2a113d7bdf716db3ca8e3243f735dcecaba"},
-    {file = "identify-2.5.27.tar.gz", hash = "sha256:287b75b04a0e22d727bc9a41f0d4f3c1bcada97490fa6eabb5b28f0e9097e733"},
+    {file = "identify-2.5.28-py2.py3-none-any.whl", hash = "sha256:87816de144bf46d161bd5b3e8f5596b16cade3b80be537087334b26bc5c177f3"},
+    {file = "identify-2.5.28.tar.gz", hash = "sha256:94bb59643083ebd60dc996d043497479ee554381fbc5307763915cda49b0e78f"},
 ]
 
 [package.extras]
@@ -2019,14 +2039,14 @@ test = ["appdirs (==1.4.4)", "covdefaults (>=2.3)", "pytest (>=7.4)", "pytest-co
 
 [[package]]
 name = "pluggy"
-version = "1.2.0"
+version = "1.3.0"
 description = "plugin and hook calling mechanisms for python"
 category = "dev"
 optional = false
-python-versions = ">=3.7"
+python-versions = ">=3.8"
 files = [
-    {file = "pluggy-1.2.0-py3-none-any.whl", hash = "sha256:c2fd55a7d7a3863cba1a013e4e2414658b1d07b6bc57b3919e0c63c9abb99849"},
-    {file = "pluggy-1.2.0.tar.gz", hash = "sha256:d12f0c4b579b15f5e054301bb226ee85eeeba08ffec228092f8defbaa3a4c4b3"},
+    {file = "pluggy-1.3.0-py3-none-any.whl", hash = "sha256:d89c696a773f8bd377d18e5ecda92b7a3793cbe66c87060a6fb58c7b6e1061f7"},
+    {file = "pluggy-1.3.0.tar.gz", hash = "sha256:cf61ae8f126ac6f7c451172cf30e3e43d3ca77615509771b3a984a0730651e12"},
 ]
 
 [package.extras]
@@ -2050,14 +2070,14 @@ six = ">=1.5.2"
 
 [[package]]
 name = "pre-commit"
-version = "3.3.3"
+version = "3.4.0"
 description = "A framework for managing and maintaining multi-language pre-commit hooks."
 category = "dev"
 optional = false
 python-versions = ">=3.8"
 files = [
-    {file = "pre_commit-3.3.3-py2.py3-none-any.whl", hash = "sha256:10badb65d6a38caff29703362271d7dca483d01da88f9d7e05d0b97171c136cb"},
-    {file = "pre_commit-3.3.3.tar.gz", hash = "sha256:a2256f489cd913d575c145132ae196fe335da32d91a8294b7afe6622335dd023"},
+    {file = "pre_commit-3.4.0-py2.py3-none-any.whl", hash = "sha256:96d529a951f8b677f730a7212442027e8ba53f9b04d217c4c67dc56c393ad945"},
+    {file = "pre_commit-3.4.0.tar.gz", hash = "sha256:6bbd5129a64cad4c0dfaeeb12cd8f7ea7e15b77028d985341478c8af3c759522"},
 ]
 
 [package.dependencies]
@@ -2403,14 +2423,14 @@ testutils = ["gitpython (>3)"]
 
 [[package]]
 name = "pytest"
-version = "7.4.0"
+version = "7.4.2"
 description = "pytest: simple powerful testing with Python"
 category = "dev"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "pytest-7.4.0-py3-none-any.whl", hash = "sha256:78bf16451a2eb8c7a2ea98e32dc119fd2aa758f1d5d66dbf0a59d69a3969df32"},
-    {file = "pytest-7.4.0.tar.gz", hash = "sha256:b4bf8c45bd59934ed84001ad51e11b4ee40d40a1229d2c79f9c592b0a3f6bd8a"},
+    {file = "pytest-7.4.2-py3-none-any.whl", hash = "sha256:1d881c6124e08ff0a1bb75ba3ec0bfd8b5354a01c194ddd5a0a870a48d99b002"},
+    {file = "pytest-7.4.2.tar.gz", hash = "sha256:a766259cfab564a2ad52cb1aae1b881a75c3eb7e34ca3779697c23ed47c47069"},
 ]
 
 [package.dependencies]
@@ -2696,14 +2716,14 @@ jupyter = ["ipywidgets (>=7.5.1,<9)"]
 
 [[package]]
 name = "sentry-sdk"
-version = "1.29.2"
+version = "1.30.0"
 description = "Python client for Sentry (https://sentry.io)"
 category = "main"
 optional = false
 python-versions = "*"
 files = [
-    {file = "sentry-sdk-1.29.2.tar.gz", hash = "sha256:a99ee105384788c3f228726a88baf515fe7b5f1d2d0f215a03d194369f158df7"},
-    {file = "sentry_sdk-1.29.2-py2.py3-none-any.whl", hash = "sha256:3e17215d8006612e2df02b0e73115eb8376c37e3f586d8436fa41644e605074d"},
+    {file = "sentry-sdk-1.30.0.tar.gz", hash = "sha256:7dc873b87e1faf4d00614afd1058bfa1522942f33daef8a59f90de8ed75cd10c"},
+    {file = "sentry_sdk-1.30.0-py2.py3-none-any.whl", hash = "sha256:2e53ad63f96bb9da6570ba2e755c267e529edcf58580a2c0d2a11ef26e1e678b"},
 ]
 
 [package.dependencies]
@@ -2726,6 +2746,7 @@ httpx = ["httpx (>=0.16.0)"]
 huey = ["huey (>=2)"]
 loguru = ["loguru (>=0.5)"]
 opentelemetry = ["opentelemetry-distro (>=0.35b0)"]
+opentelemetry-experimental = ["opentelemetry-distro (>=0.40b0,<1.0)", "opentelemetry-instrumentation-aiohttp-client (>=0.40b0,<1.0)", "opentelemetry-instrumentation-django (>=0.40b0,<1.0)", "opentelemetry-instrumentation-fastapi (>=0.40b0,<1.0)", "opentelemetry-instrumentation-flask (>=0.40b0,<1.0)", "opentelemetry-instrumentation-requests (>=0.40b0,<1.0)", "opentelemetry-instrumentation-sqlite3 (>=0.40b0,<1.0)", "opentelemetry-instrumentation-urllib (>=0.40b0,<1.0)"]
 pure-eval = ["asttokens", "executing", "pure-eval"]
 pymongo = ["pymongo (>=3.1)"]
 pyspark = ["pyspark (>=2.4.4)"]
@@ -2739,20 +2760,20 @@ tornado = ["tornado (>=5)"]
 
 [[package]]
 name = "setuptools"
-version = "68.1.2"
+version = "68.2.2"
 description = "Easily download, build, install, upgrade, and uninstall Python packages"
 category = "dev"
 optional = false
 python-versions = ">=3.8"
 files = [
-    {file = "setuptools-68.1.2-py3-none-any.whl", hash = "sha256:3d8083eed2d13afc9426f227b24fd1659489ec107c0e86cec2ffdde5c92e790b"},
-    {file = "setuptools-68.1.2.tar.gz", hash = "sha256:3d4dfa6d95f1b101d695a6160a7626e15583af71a5f52176efa5d39a054d475d"},
+    {file = "setuptools-68.2.2-py3-none-any.whl", hash = "sha256:b454a35605876da60632df1a60f736524eb73cc47bbc9f3f1ef1b644de74fd2a"},
+    {file = "setuptools-68.2.2.tar.gz", hash = "sha256:4ac1475276d2f1c48684874089fefcd83bd7162ddaafb81fac866ba0db282a87"},
 ]
 
 [package.extras]
-docs = ["furo", "jaraco.packaging (>=9.3)", "jaraco.tidelift (>=1.4)", "pygments-github-lexers (==0.0.5)", "rst.linker (>=1.9)", "sphinx (>=3.5,<=7.1.2)", "sphinx-favicon", "sphinx-hoverxref (<2)", "sphinx-inline-tabs", "sphinx-lint", "sphinx-notfound-page (==0.8.3)", "sphinx-reredirects", "sphinxcontrib-towncrier"]
+docs = ["furo", "jaraco.packaging (>=9.3)", "jaraco.tidelift (>=1.4)", "pygments-github-lexers (==0.0.5)", "rst.linker (>=1.9)", "sphinx (>=3.5)", "sphinx-favicon", "sphinx-hoverxref (<2)", "sphinx-inline-tabs", "sphinx-lint", "sphinx-notfound-page (>=1,<2)", "sphinx-reredirects", "sphinxcontrib-towncrier"]
 testing = ["build[virtualenv]", "filelock (>=3.4.0)", "flake8-2020", "ini2toml[lite] (>=0.9)", "jaraco.develop (>=7.21)", "jaraco.envs (>=2.2)", "jaraco.path (>=3.2.0)", "pip (>=19.1)", "pytest (>=6)", "pytest-black (>=0.3.7)", "pytest-checkdocs (>=2.4)", "pytest-cov", "pytest-enabler (>=2.2)", "pytest-mypy (>=0.9.1)", "pytest-perf", "pytest-ruff", "pytest-timeout", "pytest-xdist", "tomli-w (>=1.0.0)", "virtualenv (>=13.0.0)", "wheel"]
-testing-integration = ["build[virtualenv]", "filelock (>=3.4.0)", "jaraco.envs (>=2.2)", "jaraco.path (>=3.2.0)", "pytest", "pytest-enabler", "pytest-xdist", "tomli", "virtualenv (>=13.0.0)", "wheel"]
+testing-integration = ["build[virtualenv] (>=1.0.3)", "filelock (>=3.4.0)", "jaraco.envs (>=2.2)", "jaraco.path (>=3.2.0)", "packaging (>=23.1)", "pytest", "pytest-enabler", "pytest-xdist", "tomli", "virtualenv (>=13.0.0)", "wheel"]
 
 [[package]]
 name = "six"
@@ -3056,6 +3077,7 @@ files = [
 [package.dependencies]
 asyncpg = {version = "*", optional = true, markers = "extra == \"postgresql_asyncpg\""}
 greenlet = {version = "!=0.4.17", markers = "platform_machine == \"aarch64\" or platform_machine == \"ppc64le\" or platform_machine == \"x86_64\" or platform_machine == \"amd64\" or platform_machine == \"AMD64\" or platform_machine == \"win32\" or platform_machine == \"WIN32\""}
+mypy = {version = ">=0.910", optional = true, markers = "extra == \"mypy\""}
 typing-extensions = ">=4.2.0"
 
 [package.extras]
@@ -3279,14 +3301,14 @@ standard = ["colorama (>=0.4)", "httptools (>=0.5.0)", "python-dotenv (>=0.13)",
 
 [[package]]
 name = "virtualenv"
-version = "20.24.3"
+version = "20.24.5"
 description = "Virtual Python Environment builder"
 category = "dev"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "virtualenv-20.24.3-py3-none-any.whl", hash = "sha256:95a6e9398b4967fbcb5fef2acec5efaf9aa4972049d9ae41f95e0972a683fd02"},
-    {file = "virtualenv-20.24.3.tar.gz", hash = "sha256:e5c3b4ce817b0b328af041506a2a299418c98747c4b1e68cb7527e74ced23efc"},
+    {file = "virtualenv-20.24.5-py3-none-any.whl", hash = "sha256:b80039f280f4919c77b30f1c23294ae357c4c8701042086e3fc005963e4e537b"},
+    {file = "virtualenv-20.24.5.tar.gz", hash = "sha256:e8361967f6da6fbdf1426483bfe9fca8287c242ac0bc30429905721cefbff752"},
 ]
 
 [package.dependencies]
@@ -3295,7 +3317,7 @@ filelock = ">=3.12.2,<4"
 platformdirs = ">=3.9.1,<4"
 
 [package.extras]
-docs = ["furo (>=2023.5.20)", "proselint (>=0.13)", "sphinx (>=7.0.1)", "sphinx-argparse (>=0.4)", "sphinxcontrib-towncrier (>=0.2.1a0)", "towncrier (>=23.6)"]
+docs = ["furo (>=2023.7.26)", "proselint (>=0.13)", "sphinx (>=7.1.2)", "sphinx-argparse (>=0.4)", "sphinxcontrib-towncrier (>=0.2.1a0)", "towncrier (>=23.6)"]
 test = ["covdefaults (>=2.3)", "coverage (>=7.2.7)", "coverage-enable-subprocess (>=1)", "flaky (>=3.7)", "packaging (>=23.1)", "pytest (>=7.4)", "pytest-env (>=0.8.2)", "pytest-freezer (>=0.4.8)", "pytest-mock (>=3.11.1)", "pytest-randomly (>=3.12)", "pytest-timeout (>=2.1)", "setuptools (>=68)", "time-machine (>=2.10)"]
 
 [[package]]
@@ -3528,4 +3550,4 @@ multidict = ">=4.0"
 [metadata]
 lock-version = "2.0"
 python-versions = "^3.11"
-content-hash = "f0ebcec9a204aa7a3d7fb4b0c49ac1eae0f4c7c24ab3fad791afd978aedbe5e7"
+content-hash = "acb2894d15e7fa1ae4e2e3a97d4c9c19e5d35e464827dca16cb26f8425f6cd4d"
diff --git a/pyproject.toml b/pyproject.toml
index 257c195..f0f6c6d 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -33,7 +33,7 @@ aioresponses = "~0.7.3"
 autoflake = "^2.0.1"
 bandit = "^1.7.4"
 black = { extras = ['d'], version = "^22.12.0" }
-flake8 = "^6.0.0"
+flake8 = {extras = ["pyflakes"], version = "^6.1.0"}
 flake8-blind-except = "^0.2.1"
 flake8-bugbear = "^23.1.20"
 flake8-builtins = "^2.1.0"
@@ -45,6 +45,7 @@ flake8-docstrings = "~1.7.0"
 flake8-implicit-str-concat = "^0.3.0"
 flake8-isort = "^6.0.0"
 flake8-module-name = "^0.2.0"
+flake8-mypy = "^17.8.0"
 flake8-pep3101 = "^2.0"
 flake8-print = "^5.0"
 flake8-pyproject = "^1.2.2"
@@ -74,6 +75,7 @@ requests = "~2.28.2"
 Sphinx = "~5.3.0"
 sphinx-autodoc-typehints = "^1.11"
 sphinxcontrib-napoleon = "^0.7.0"
+sqlalchemy = {extras = ["mypy"], version = "^2.0.20"}
 types-docutils = "^0.19.1.4"
 types-pyopenssl = "^23.0.0.3"
 types-python-dateutil = "^2.8.19.7"
@@ -170,7 +172,8 @@ exclude = [
     "config/gunicorn.py"
 ]
 plugins = [
-  "pydantic.mypy"
+  "pydantic.mypy",
+  "sqlalchemy.ext.mypy.plugin"
 ]
 
 allow_redefinition = false
diff --git a/src/app/controller/http/health_check.py b/src/app/controller/http/health_check.py
index ac2e280..72edabb 100644
--- a/src/app/controller/http/health_check.py
+++ b/src/app/controller/http/health_check.py
@@ -1,10 +1,9 @@
-import typing as t
 import logging
 
 import prometheus_client as pc
 from fastapi import APIRouter, Request, status
 from fastapi.responses import PlainTextResponse
-from sqlalchemy.engine.result import Result
+from sqlalchemy import text
 
 from src.app.dto import ErrorResponse, ReadyResponse
 from src.app.exceptions import HTTPException
@@ -29,9 +28,9 @@ async def ping(request: Request) -> ReadyResponse:
     """ping."""
     try:
         async with AsyncDBClient.async_engine.begin() as conn:
-            res: t.Awaitable[Result] = await conn.execute("SELECT 1;")
-            return ReadyResponse(status=f"ok: true; db: {bool(await res.scalar())}")
-    except Exception:
+            res = await conn.execute(text("SELECT 1;"))
+            return ReadyResponse(status=f"ok: true; db: {bool(res.scalar())}")
+    except Exception as exc:
         log.exception("ping db fail")
         raise HTTPException(
             status.HTTP_502_BAD_GATEWAY,
@@ -39,7 +38,7 @@ async def ping(request: Request) -> ReadyResponse:
                 code=status.HTTP_502_BAD_GATEWAY,
                 message="Could not connect to PostgreSQL",
             ).model_dump(exclude_none=True),
-        )
+        ) from exc
 
 
 @srv_router.get("/metrics")
diff --git a/src/app/entity/base.py b/src/app/entity/base.py
index aeeeeee..8ee722a 100644
--- a/src/app/entity/base.py
+++ b/src/app/entity/base.py
@@ -1,13 +1,4 @@
-import typing as t
-
-from uuid import UUID
-
-import sqlalchemy as sa
-from multimethod import multimethod as overload
 from sqlalchemy import MetaData
-from sqlalchemy.dialects import postgresql as psql
-from sqlalchemy.exc import NoResultFound
-from sqlalchemy.ext.asyncio import AsyncSession
 from sqlalchemy.ext.declarative import as_declarative, declared_attr
 
 convention = {
@@ -23,14 +14,7 @@ convention = {
 class Base:
 
     __name__: str
-    metadata: MetaData(naming_convention=convention)
-
-    id = sa.Column(  # noqa: A003
-        psql.UUID(as_uuid=True),
-        server_default=sa.text("gen_random_uuid()"),
-        primary_key=True,
-        index=True,
-    )
+    metadata: MetaData(naming_convention=convention)  # type: ignore
 
     def __repr__(self) -> str:  # noqa: D105
         columns = ", ".join(
@@ -38,83 +22,6 @@ class Base:
         )
         return f"<{self.__class__.__name__}({columns})>"
 
-    @classmethod
     @declared_attr
     def __tablename__(cls) -> str:  # noqa: N805 D105
         return cls.__name__.lower()
-
-    @classmethod
-    def get_pk(cls, object_instance: t.Self) -> t.Dict[str, t.Any] | t.Any:
-        """Get pk."""
-        server_default_pks = (pk for pk in cls.__mapper__.primary_key if pk.server_default is not None)
-        pks = {pk.name: attr for pk in server_default_pks if (attr := getattr(object_instance, pk.name)) is not None}
-
-        if len(pks) == 1:
-            return next(iter(pks.values()))
-        elif len(pks) > 1:
-            return pks
-
-    @classmethod
-    def has_pk(cls, object_instance: t.Self) -> bool:
-        """Model has pk."""
-        return bool(cls.get_pk(object_instance))
-
-    @classmethod
-    def merge(cls, object_instance: t.Self, **attrs) -> t.Self:
-        """Merge model instance."""
-        for attr_key, attr_value in attrs.items():
-            setattr(object_instance, attr_key, attr_value)
-
-        return object_instance
-
-    @classmethod
-    async def find_one(cls, async_session: AsyncSession, object_id: UUID) -> t.Self | None:
-        """Select from db single model by pk - id."""
-        stmt = sa.select(cls).where(cls.id == object_id)
-        return await async_session.scalar(stmt)
-
-    @classmethod
-    async def find_one_or_fail(cls, async_session: AsyncSession, object_id: UUID) -> t.Self:
-        """Find single model by pk - id."""
-        object_instance = await cls.find_one(async_session, object_id)
-        if object_instance is None:
-            raise NoResultFound(f"{cls.__name__} not found")
-        return object_instance
-
-    @classmethod
-    async def delete(cls, async_session: AsyncSession, object_id: UUID) -> None:
-        """Hard delete model instance."""
-        stmt = sa.delete(cls).where(cls.id == object_id)
-        await async_session.execute(stmt)
-        await async_session.commit()
-
-    @classmethod
-    @overload
-    async def pre_save(cls, async_session: AsyncSession, instance: t.Self, **kwargs) -> t.Self:
-        if cls.has_pk(instance):
-            return await async_session.merge(instance, **kwargs)
-
-        async_session.add(instance, **kwargs)
-        await async_session.flush([instance])
-        return instance
-
-    @classmethod
-    @overload
-    async def pre_save(cls, async_session: AsyncSession, instances: t.Sequence[t.Self]) -> t.Sequence[t.Self]:  # noqa
-        async_session.add_all(instances)
-        await async_session.flush(instances)
-        return instances
-
-    @classmethod
-    @overload
-    async def save(cls, async_session: AsyncSession, instance: t.Self, **kwargs) -> t.Self:
-        instance = await cls.pre_save(async_session, instance, **kwargs)
-        await async_session.commit()
-        return instance
-
-    @classmethod
-    @overload
-    async def save(cls, async_session: AsyncSession, instances: t.Sequence[t.Self]) -> t.Sequence[t.Self]:  # noqa
-        instances = await cls.pre_save(async_session, instances)
-        await async_session.commit()
-        return instances
diff --git a/src/app/entity/category.py b/src/app/entity/category.py
index 9014320..585f1ee 100644
--- a/src/app/entity/category.py
+++ b/src/app/entity/category.py
@@ -5,8 +5,7 @@ import typing as t
 from uuid import UUID
 
 import sqlalchemy as sa
-from sqlalchemy.dialects import postgresql as psql
-from sqlalchemy.orm import Mapped, relationship
+from sqlalchemy.orm import Mapped, mapped_column, relationship
 
 from src.app.entity.base import Base
 from src.app.entity.mixin import TimestampMixin
@@ -17,21 +16,15 @@ if t.TYPE_CHECKING:
 
 class Category(TimestampMixin, Base):
 
-    id = sa.Column(  # noqa: A003
-        psql.UUID(as_uuid=True),
-        server_default=sa.text("gen_random_uuid()"),
-        primary_key=True,
-        index=True,
-    )
-    category_title: Mapped[str] = sa.Column(sa.String(255), nullable=True)
-    category_description: Mapped[str] = sa.Column(sa.String(255), nullable=True)
+    category_title: Mapped[str] = mapped_column(sa.String(255), nullable=True)
+    category_description: Mapped[str] = mapped_column(sa.String(255), nullable=True)
 
-    parent_category_id: Mapped[list[UUID]] = sa.Column(sa.UUID, sa.ForeignKey("category.id"), nullable=True)
-    parent_category: Mapped[t.Self] = relationship(
+    parent_category_id: Mapped[list[UUID]] = mapped_column(sa.ForeignKey("category.id"), nullable=True)
+    parent_category: Mapped["t.Self"] = relationship(
         "Category",
-        remote_side=[id],
+        remote_side="category.id",
     )
-    service: Mapped[Service] = relationship(
+    service: Mapped["Service"] = relationship(
         "Service",
         secondary="category_x_service",
         back_populates="category",
diff --git a/src/app/entity/mixin.py b/src/app/entity/mixin.py
index 038c453..c849934 100644
--- a/src/app/entity/mixin.py
+++ b/src/app/entity/mixin.py
@@ -1,30 +1,129 @@
 import typing as t
 
+from datetime import datetime
 from uuid import UUID
 
 import sqlalchemy as sa
+from multimethod import multimethod as overload
+from sqlalchemy.dialects import postgresql as psql
+from sqlalchemy.exc import NoResultFound
 from sqlalchemy.ext.asyncio import AsyncSession
-from sqlalchemy.orm import declarative_mixin
+from sqlalchemy.orm import Mapped, declarative_mixin, mapped_column
+
+from src.app.entity.base import Base
+
+
+@declarative_mixin
+class IDMixin:
+
+    id: Mapped[UUID] = mapped_column(  # noqa: A003
+        psql.UUID(as_uuid=True),
+        server_default=sa.text("gen_random_uuid()"),
+        primary_key=True,
+        index=True,
+    )
+
+    @classmethod
+    def get_pk(cls, object_instance: "Base") -> t.Dict[str, t.Any] | t.Any:
+        """Get pk."""
+        server_default_pks = (pk for pk in cls.__mapper__.primary_key if pk.server_default is not None)  # type: ignore
+        pks = {
+            pk.name: attr for pk in server_default_pks if (attr := getattr(object_instance, pk.name)) is not None
+        }  # noqa, type: ignore
+
+        if len(pks) == 1:
+            return next(iter(pks.values()))
+
+        if len(pks) > 1:
+            return pks
+
+        return None
+
+    @classmethod
+    def has_pk(cls, object_instance: "Base") -> bool:
+        """Model has pk."""
+        return bool(cls.get_pk(object_instance))
+
+    @classmethod
+    def merge(cls, object_instance: "Base", **attrs: t.Any) -> "Base":
+        """Merge model instance."""
+        for attr_key, attr_value in attrs.items():
+            setattr(object_instance, attr_key, attr_value)
+
+        return object_instance
+
+    @classmethod
+    async def find_one(cls, async_session: AsyncSession, object_id: UUID) -> t.Optional["Base"]:
+        """Select from db single model by pk - id."""
+        stmt = sa.select(cls).where(cls.id == object_id)
+        return await async_session.scalar(stmt)
+
+    @classmethod
+    async def find_one_or_fail(cls, async_session: AsyncSession, object_id: UUID) -> "Base":
+        """Find single model by pk - id."""
+        object_instance = await cls.find_one(async_session, object_id)
+        if object_instance is None:
+            raise NoResultFound(f"{cls.__name__} not found")
+        return object_instance
+
+    @classmethod
+    async def delete(cls, async_session: AsyncSession, object_id: UUID) -> None:
+        """Hard delete model instance."""
+        stmt = sa.delete(cls).where(cls.id == object_id)
+        await async_session.execute(stmt)
+        await async_session.commit()
+
+    # @classmethod
+    @overload
+    async def pre_save(cls, async_session: AsyncSession, instance: "Base", **kwargs: t.Any) -> "Base":  # noqa
+        if cls.has_pk(instance):
+            return await async_session.merge(instance, **kwargs)
+
+        async_session.add(instance, **kwargs)
+        await async_session.flush([instance])
+        return instance
+
+    @classmethod
+    @pre_save.register
+    async def _(cls, async_session: AsyncSession, instances: t.Sequence["Base"]) -> t.Sequence["Base"]:  # noqa
+        async_session.add_all(instances)
+        await async_session.flush(instances)
+        return instances
+
+    # @classmethod
+    @overload
+    async def save(cls, async_session: AsyncSession, instance: "Base", **kwargs: t.Any) -> "Base":  # noqa
+        instance = await cls.pre_save(async_session, instance, **kwargs)
+        await async_session.commit()
+        return instance
+
+    @classmethod
+    @save.register
+    async def _(cls, async_session: AsyncSession, instances: t.Sequence["Base"]) -> t.Sequence["Base"]:  # noqa
+        instances = await cls.pre_save(async_session, instances)
+        await async_session.commit()
+        return instances
 
 
 @declarative_mixin
-class TimestampMixin:
+class TimestampMixin(IDMixin):
+    """Nested IDMixin (not need use IDMixin in orm model)."""
 
-    created_at = sa.Column(
+    created_at: Mapped[datetime] = mapped_column(
         sa.DateTime,
         default=sa.func.now(),
         server_default=sa.FetchedValue(),
     )
-    updated_at = sa.Column(
+    updated_at: Mapped[datetime] = mapped_column(
         sa.DateTime,
         onupdate=sa.func.now(),
         server_default=sa.FetchedValue(),
         server_onupdate=sa.FetchedValue(),
     )
-    deleted_at = sa.Column(sa.DateTime, server_default=sa.FetchedValue())
+    deleted_at: Mapped[datetime] = mapped_column(sa.DateTime, server_default=sa.FetchedValue())
 
     @classmethod
-    async def find_one(cls, async_session: AsyncSession, object_id: UUID) -> t.Self | None:
+    async def find_one(cls, async_session: AsyncSession, object_id: UUID) -> t.Optional["Base"]:
         """Select from db single model by pk - id."""
         stmt = sa.select(cls).where(
             cls.id == object_id,
@@ -35,6 +134,6 @@ class TimestampMixin:
     @classmethod
     async def delete(cls, async_session: AsyncSession, object_id: UUID) -> None:
         """Soft delete model from db."""
-        object_instance = await cls.find_one_or_fail(object_id)
+        object_instance = await cls.find_one_or_fail(async_session, object_id)
         cls.merge(object_instance, deleted_at=sa.func.now())
         await cls.save(async_session, object_instance)
diff --git a/src/app/entity/mtm_relation.py b/src/app/entity/mtm_relation.py
index e14d071..2896638 100644
--- a/src/app/entity/mtm_relation.py
+++ b/src/app/entity/mtm_relation.py
@@ -1,28 +1,20 @@
-from __future__ import annotations
-
-import typing as t
+from uuid import UUID
 
 import sqlalchemy as sa
-from sqlalchemy.orm import Mapped
+from sqlalchemy.orm import Mapped, mapped_column
 
 from src.app.entity.base import Base
 
-if t.TYPE_CHECKING:
-    from src.app.entity.category import Category
-    from src.app.entity.service import Service
-
 
 class CategoryXService(Base):
 
-    __tablename__ = "category_x_service"
+    __tablename__ = "category_x_service"  # type: ignore
 
-    category_id: Mapped[Category] = sa.Column(
-        sa.UUID,
+    category_id: Mapped[UUID] = mapped_column(
         sa.ForeignKey("category.id"),
         primary_key=True,
     )
-    service_id: Mapped[Service] = sa.Column(
-        sa.UUID,
+    service_id: Mapped[UUID] = mapped_column(
         sa.ForeignKey("service.id"),
         primary_key=True,
     )
diff --git a/src/app/entity/provider_contact.py b/src/app/entity/provider_contact.py
index e79e39d..79fc646 100644
--- a/src/app/entity/provider_contact.py
+++ b/src/app/entity/provider_contact.py
@@ -3,7 +3,7 @@ from __future__ import annotations
 import typing as t
 
 import sqlalchemy as sa
-from sqlalchemy.orm import Mapped, relationship
+from sqlalchemy.orm import Mapped, mapped_column, relationship
 
 from src.app.entity.base import Base
 from src.app.entity.mixin import TimestampMixin
@@ -15,18 +15,18 @@ if t.TYPE_CHECKING:
 
 class ProviderContact(TimestampMixin, Base):
 
-    name: Mapped[str] = sa.Column(sa.String(255), nullable=False)
-    phone: Mapped[str] = sa.Column(sa.String(255), nullable=True)
-    email: Mapped[str] = sa.Column(sa.String(255), nullable=True)
-    additional_info: Mapped[str] = sa.Column(sa.String(255), nullable=True)
+    name: Mapped[str] = mapped_column(sa.String(255), nullable=False)
+    phone: Mapped[str] = mapped_column(sa.String(255), nullable=True)
+    email: Mapped[str] = mapped_column(sa.String(255), nullable=True)
+    additional_info: Mapped[str] = mapped_column(sa.String(255), nullable=True)
 
-    provider_entity: Mapped[list[ProviderEnity]] = relationship(
+    provider_entity: Mapped[list["ProviderEnity"]] = relationship(
         "ProviderEnity",
         back_populates="provider_contact",
         order_by="ProviderEnity.id",
         # cascade="save-update, merge, refresh-expire, expunge, delete, delete-orphan",
     )
-    provider_photo: Mapped[list[ProviderPhoto]] = relationship(
+    provider_photo: Mapped[list["ProviderPhoto"]] = relationship(
         "ProviderPhoto",
         back_populates="provider_contact",
         order_by="ProviderPhoto.id",
diff --git a/src/app/entity/provider_entity.py b/src/app/entity/provider_entity.py
index 2aafccc..a5aee76 100644
--- a/src/app/entity/provider_entity.py
+++ b/src/app/entity/provider_entity.py
@@ -5,7 +5,7 @@ import typing as t
 from uuid import UUID
 
 import sqlalchemy as sa
-from sqlalchemy.orm import Mapped, relationship
+from sqlalchemy.orm import Mapped, mapped_column, relationship
 
 from src.app.entity.base import Base
 from src.app.entity.mixin import TimestampMixin
@@ -17,21 +17,24 @@ if t.TYPE_CHECKING:
 
 class ProviderEnity(TimestampMixin, Base):
 
-    address: Mapped[str] = sa.Column(sa.String(255), nullable=True)
-    primary_phone: Mapped[str] = sa.Column(sa.String(255), nullable=True)
-    secondary_phone: Mapped[str] = sa.Column(sa.String(255), nullable=True)
-    lat: Mapped[float] = sa.Column(sa.Numeric(8, 6), nullable=True)
-    lon: Mapped[float] = sa.Column(sa.Numeric(8, 6), nullable=True)
+    address: Mapped[str] = mapped_column(sa.String(255), nullable=True)
+    primary_phone: Mapped[str] = mapped_column(sa.String(255), nullable=True)
+    secondary_phone: Mapped[str] = mapped_column(sa.String(255), nullable=True)
+    lat: Mapped[float] = mapped_column(sa.Numeric(8, 6), nullable=True)
+    lon: Mapped[float] = mapped_column(sa.Numeric(8, 6), nullable=True)
 
-    provider_contact_id: Mapped[list[UUID]] = sa.Column(sa.UUID, sa.ForeignKey("providercontact.id"), nullable=True)
+    provider_contact_id: Mapped[list[UUID]] = mapped_column(
+        sa.ForeignKey("providercontact.id"),
+        nullable=True,
+    )
 
-    provider_contact: Mapped[list[ProviderContact]] = relationship(
+    provider_contact: Mapped[list["ProviderContact"]] = relationship(
         "ProviderContact",
         back_populates="provider_entity",
         order_by="ProviderContact.id",
         # cascade="save-update, merge, refresh-expire, expunge, delete, delete-orphan",
     )
-    service: Mapped[list[Service]] = relationship(
+    service: Mapped[list["Service"]] = relationship(
         "Service",
         back_populates="provider_entity",
         order_by="Service.id",
diff --git a/src/app/entity/provider_photo.py b/src/app/entity/provider_photo.py
index 759d114..3429a26 100644
--- a/src/app/entity/provider_photo.py
+++ b/src/app/entity/provider_photo.py
@@ -5,21 +5,22 @@ import typing as t
 from uuid import UUID
 
 import sqlalchemy as sa
-from sqlalchemy.orm import Mapped, relationship
+from sqlalchemy.orm import Mapped, mapped_column, relationship
 
 from src.app.entity.base import Base
+from src.app.entity.mixin import IDMixin
 
 if t.TYPE_CHECKING:
     from src.app.entity.provider_contact import ProviderContact
 
 
-class ProviderPhoto(Base):
+class ProviderPhoto(IDMixin, Base):
 
-    picture_path: Mapped[str] = sa.Column(sa.String(255), nullable=True)
+    picture_path: Mapped[str] = mapped_column(sa.String(255), nullable=True)
 
-    provider_contact_id: Mapped[list[UUID]] = sa.Column(sa.UUID, sa.ForeignKey("providercontact.id"), nullable=True)
+    provider_contact_id: Mapped[list[UUID]] = mapped_column(sa.ForeignKey("providercontact.id"), nullable=True)
 
-    provider_contact: Mapped[list[ProviderContact]] = relationship(
+    provider_contact: Mapped[list["ProviderContact"]] = relationship(
         "ProviderContact",
         back_populates="provider_photo",
         order_by="ProviderContact.id",
diff --git a/src/app/entity/service.py b/src/app/entity/service.py
index 609e373..3d616f4 100644
--- a/src/app/entity/service.py
+++ b/src/app/entity/service.py
@@ -5,7 +5,7 @@ import typing as t
 from uuid import UUID
 
 import sqlalchemy as sa
-from sqlalchemy.orm import Mapped, relationship
+from sqlalchemy.orm import Mapped, mapped_column, relationship
 
 from src.app.entity.base import Base
 from src.app.entity.mixin import TimestampMixin
@@ -17,19 +17,19 @@ if t.TYPE_CHECKING:
 
 class Service(TimestampMixin, Base):
 
-    name: Mapped[str] = sa.Column(sa.String(255), nullable=False)
-    url: Mapped[str] = sa.Column(sa.String(255), nullable=True)
-    operating_hours: Mapped[str] = sa.Column(sa.String(255), nullable=True)
+    name: Mapped[str] = mapped_column(sa.String(255), nullable=False)
+    url: Mapped[str] = mapped_column(sa.String(255), nullable=True)
+    operating_hours: Mapped[str] = mapped_column(sa.String(255), nullable=True)
 
-    provider_entity_id: Mapped[list[UUID]] = sa.Column(sa.UUID, sa.ForeignKey("providerenity.id"), nullable=True)
+    provider_entity_id: Mapped[list[UUID]] = mapped_column(sa.ForeignKey("providerenity.id"), nullable=True)
 
-    provider_entity: Mapped[list[ProviderEnity]] = relationship(
+    provider_entity: Mapped[list["ProviderEnity"]] = relationship(
         "ProviderEnity",
         back_populates="service",
         order_by="Service.id",
         # cascade="save-update, merge, refresh-expire, expunge, delete, delete-orphan",
     )
-    category: Mapped[list[Category]] = relationship(
+    category: Mapped[list["Category"]] = relationship(
         "Category",
         secondary="category_x_service",
         back_populates="service",
diff --git a/src/app/entity/user.py b/src/app/entity/user.py
index 46d29a5..0b99f70 100644
--- a/src/app/entity/user.py
+++ b/src/app/entity/user.py
@@ -1,4 +1,5 @@
 import sqlalchemy as sa
+from sqlalchemy.orm import Mapped, mapped_column
 
 from src.app.entity.base import Base
 from src.app.entity.mixin import TimestampMixin
@@ -11,6 +12,6 @@ class User(TimestampMixin, Base):
         sa.UniqueConstraint("email"),
     )
 
-    username = sa.Column(sa.String(255), nullable=False)
-    phone = sa.Column(sa.String(255), nullable=True)
-    email = sa.Column(sa.String(255), index=True, nullable=False)
+    username: Mapped[str] = mapped_column(sa.String(255), nullable=False)
+    phone: Mapped[str] = mapped_column(sa.String(255), nullable=True)
+    email: Mapped[str] = mapped_column(sa.String(255), index=True, nullable=False)
diff --git a/src/app/metrics/metrics.py b/src/app/metrics/metrics.py
index f428f35..527b4df 100644
--- a/src/app/metrics/metrics.py
+++ b/src/app/metrics/metrics.py
@@ -4,11 +4,10 @@ import time
 from urllib.parse import urlparse
 
 import prometheus_client as pc
-from httpx import Response
+from aiohttp import ClientResponse
 
 from src.config import settings
 
-T = t.TypeVar("T")
 P = t.ParamSpec("P")
 
 
@@ -50,7 +49,9 @@ request_timings = pc.Histogram(
 )
 
 
-def observe_request(func: t.Callable[P, T]) -> t.Callable[P, T]:
+def observe_request(
+    func: t.Callable[P, t.Awaitable[ClientResponse]],
+) -> t.Callable[P, t.Coroutine[t.Any, t.Any, ClientResponse]]:
     """Observe request to service.
 
     :param func: _description_
@@ -59,13 +60,13 @@ def observe_request(func: t.Callable[P, T]) -> t.Callable[P, T]:
     :rtype: t.Callable[P, T]
     """
 
-    async def _wrap(*args: P.args, **kwargs: P.kwargs) -> Response:  # type: ignore
+    async def _wrap(*args: P.args, **kwargs: P.kwargs) -> ClientResponse:
         ts_start = time.monotonic()
         try:
-            resp: Response = await func(*args, **kwargs)  # type: ignore
+            resp: ClientResponse = await func(*args, **kwargs)
             elapsed = time.monotonic() - ts_start
 
-            entity = urlparse(resp.url).netloc  # type: ignore
+            entity = urlparse(str(resp.url)).netloc
 
             request_timings.labels(entity).observe(elapsed)
 
diff --git a/src/app/modules/db_client.py b/src/app/modules/db_client.py
index be64ab0..c1e30b6 100644
--- a/src/app/modules/db_client.py
+++ b/src/app/modules/db_client.py
@@ -4,7 +4,7 @@ import logging
 import time
 from uuid import uuid4
 
-from sqlalchemy.engine.result import Result
+from sqlalchemy import text
 from sqlalchemy.engine.row import Row
 from sqlalchemy.exc import SQLAlchemyError
 from sqlalchemy.ext.asyncio import (
@@ -19,8 +19,9 @@ from src.config import settings
 
 class AsyncDBClient:
 
-    async_engine: t.Optional[AsyncEngine] = None
-    AsyncSessionLocal: t.Optional[async_sessionmaker[AsyncSession]] = None
+    _connection_flg: bool = False
+    async_engine: AsyncEngine
+    AsyncSessionLocal: async_sessionmaker[AsyncSession]
     log: logging.Logger = logging.getLogger(__name__)
 
     @classmethod
@@ -30,7 +31,7 @@ class AsyncDBClient:
         :return: _description_
         :rtype: AsyncEngine
         """
-        if cls.async_engine is None:
+        if not cls._connection_flg:
             cls.log.debug("Initialize AsyncEngine.")
             cls.async_engine = create_async_engine(
                 settings.DB_URI,
@@ -43,15 +44,18 @@ class AsyncDBClient:
                 autoflush=False,
                 future=True,
             )
+            cls._connection_flg = True
         return cls.async_engine
 
     @classmethod
     async def close_db_engine(cls) -> None:
         """Dispose of the connection pool used by this _asyncio.AsyncEngine."""
-        await cls.async_engine.dispose()
+        if cls._connection_flg:
+            await cls.async_engine.dispose()
+            cls._connection_flg = False
 
     @classmethod
-    async def _get_session(cls) -> t.AsyncIterator[async_sessionmaker]:
+    async def _get_session(cls) -> t.AsyncIterator[async_sessionmaker[AsyncSession]]:
         """Helper."""
         try:
             yield cls.AsyncSessionLocal
@@ -59,7 +63,7 @@ class AsyncDBClient:
             cls.log.exception(e)
 
     @classmethod
-    async def get_session(cls) -> async_sessionmaker:
+    async def get_session(cls) -> async_sessionmaker[AsyncSession]:
         """Get async db session.
 
         :return: _description_
@@ -71,10 +75,10 @@ class AsyncDBClient:
     async def iter_cursor(
         cls,
         query: str,
-        params: t.Dict[str, t.Any],
+        params: t.Mapping[str, t.Any],
         batch_size: int = 1_000,
         cur_name_: str | None = None,
-    ) -> t.AsyncIterator[t.Sequence[Row]]:
+    ) -> t.AsyncIterator[t.Sequence[Row[t.Any]]]:
         """Server side db cursor."""
         cur_name = f"cur_{cur_name_ or uuid4().hex}_{time.time_ns()}"
         query_cursor = f"DECLARE {cur_name} CURSOR FOR {query}"
@@ -82,11 +86,11 @@ class AsyncDBClient:
         params_next_page = {"batch_size": batch_size}
 
         async with cls.async_engine.begin() as conn:
-            await conn.execute(query_cursor, params)
+            await conn.execute(text(query_cursor), params)
 
             while True:
-                res: Result = await conn.execute(query_next_page, params_next_page)
-                batch = await res.fetchall()
+                res = await conn.execute(text(query_next_page), params_next_page)
+                batch = res.fetchall()
                 if not len(batch):
                     return
                 yield batch
diff --git a/src/app/modules/http_client.py b/src/app/modules/http_client.py
index 05e627c..ff058b7 100644
--- a/src/app/modules/http_client.py
+++ b/src/app/modules/http_client.py
@@ -24,8 +24,9 @@ class AiohttpClient:
     https://gist.github.com/imbolc/15cab07811c32e7d50cc12f380f7f62f
     """
 
+    _client_flg: bool = False
     sem: asyncio.Semaphore = asyncio.Semaphore(10)
-    aiohttp_client: t.Optional[aiohttp.ClientSession] = None
+    aiohttp_client: aiohttp.ClientSession
     log: logging.Logger = logging.getLogger(__name__)
 
     @classmethod
@@ -36,7 +37,7 @@ class AiohttpClient:
             AsyncClient: AsyncClient object instance.
 
         """
-        if cls.aiohttp_client is None:
+        if not cls._client_flg:
             cls.log.debug("Initialize AiohttpClient session.")
             timeout = aiohttp.ClientTimeout(total=2)
             connector = aiohttp.TCPConnector(
@@ -47,16 +48,17 @@ class AiohttpClient:
                 timeout=timeout,
                 connector=connector,
             )
+            cls._client_flg = True
 
         return cls.aiohttp_client
 
     @classmethod
     async def close_aiohttp_client(cls) -> None:
         """Close aiohttp client session."""
-        if cls.aiohttp_client:
+        if cls._client_flg:
             cls.log.debug("Close AiohttpClient session.")
             await cls.aiohttp_client.close()
-            cls.aiohttp_client = None
+            cls._client_flg = False
 
     @classmethod
     @backoff.on_exception(
diff --git a/src/app/modules/sentry.py b/src/app/modules/sentry.py
index f4a58a2..e9d39e5 100644
--- a/src/app/modules/sentry.py
+++ b/src/app/modules/sentry.py
@@ -7,9 +7,9 @@ from src.config import settings
 log = logging.getLogger(__name__)
 
 
-def init_sentry(sentry_dsn: str = settings.SENTRY_DSN):  # pragma: no cover
+def init_sentry(sentry_dsn: str = settings.SENTRY_DSN) -> None:
     """Init sentry."""
-    if sentry_dsn is None:
+    if not sentry_dsn:
         log.warning("sentry dsn is not set")
         return
 
diff --git a/src/app/modules/thread_client.py b/src/app/modules/thread_client.py
index b88f8db..c744cce 100644
--- a/src/app/modules/thread_client.py
+++ b/src/app/modules/thread_client.py
@@ -15,27 +15,31 @@ class ThreadClient:
 
     """
 
+    thread_flg: bool = False
     n_workers: int = 2
-    thread_executor: t.Optional[concurrent.futures.ThreadPoolExecutor] = None
-    loop: t.Optional[asyncio.AbstractEventLoop] = None
+    thread_executor: concurrent.futures.ThreadPoolExecutor
+    loop: asyncio.AbstractEventLoop
     log: logging.Logger = logging.getLogger(__name__)
 
     @classmethod
     def get_thread_pool_client(cls) -> concurrent.futures.ThreadPoolExecutor:
         """Create Thread pool."""
-        if cls.thread_executor is None:
+        if not cls.thread_flg:
             cls.thread_executor = concurrent.futures.ThreadPoolExecutor(cls.n_workers)
             cls.loop = asyncio.get_running_loop()
+            cls.thread_flg = True
 
         return cls.thread_executor
 
     @classmethod
     async def close_thread_pool_executor(cls) -> None:
         """Close tread pool."""
-        cls.thread_executor.shutdown(wait=True)
+        if cls.thread_flg:
+            cls.thread_executor.shutdown(wait=True)
+            cls.thread_flg = False
 
     @classmethod
-    async def execute(cls, func: t.Callable, *args: t.Any) -> t.Any:
+    async def execute(cls, func: t.Callable[..., t.Any], *args: t.Any) -> t.Any:
         """Exec func in treads."""
         thread_executor = cls.get_thread_pool_client()
 
